[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["ouro_rl"]

[project]
name = "ouro-rl"
version = "0.1.0"
description = "Exploration of Ouro LM with RL"
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "accelerate>=1.12.0",
    "datasets>=4.5.0",
    "flash-attn",
    "huggingface-hub>=0.36.2",
    "lm-eval>=0.4.11",
    "math-verify>=0.9.0",
    "matplotlib>=3.10.8",
    "torch==2.9.1",
    "transformers>=4.57.6",
    "vllm>=0.15.1",
    "wandb>=0.25.0",
]

[dependency-groups]
dev = [
    "pytest>=9.0.2",
    "ruff>=0.15.1",
]

[tool.ruff]
line-length = 127
target-version = "py312"

[tool.ruff.lint]
select = [
    "E",    # pycodestyle errors
    "W",    # pycodestyle warnings
    "F",    # pyflakes
    "I",    # isort
    "B",    # flake8-bugbear
    "C4",   # flake8-comprehensions
    "UP",   # pyupgrade
    "ARG",  # flake8-unused-arguments
    "SIM",  # flake8-simplify
]
ignore = [
    "E501",  # line too long (handled by formatter)
    "B008",  # do not perform function calls in argument defaults
    "B905",  # zip without explicit strict parameter
]

[tool.ruff.lint.per-file-ignores]
"__init__.py" = ["F401"]  # Allow unused imports in __init__.py
"tests/**/*.py" = ["ARG"]  # Allow unused arguments in tests
"ouro_rl/modeling/modeling_ouro.py" = ["ARG"]  # Upstream code, signatures must match

[tool.ruff.format]
quote-style = "double"
indent-style = "space"

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
markers = [
    "slow: marks tests as slow (deselect with '-m \"not slow\"')",
    "integration: marks tests as integration tests",
]
filterwarnings = [
    "ignore::DeprecationWarning:importlib._bootstrap",  # SwigPyPacked/SwigPyObject from CUDA libs
    "ignore:This process.*is multi-threaded.*use of fork:DeprecationWarning",  # vLLM worker spawning
]

[tool.uv.sources]
flash-attn = { url = "https://github.com/Dao-AILab/flash-attention/releases/download/v2.8.3/flash_attn-2.8.3+cu12torch2.9cxx11abiTRUE-cp312-cp312-linux_x86_64.whl" }
torch = { index = "pytorch-cu128" }

[[tool.uv.index]]
name = "pytorch-cu128"
url = "https://download.pytorch.org/whl/cu128"
explicit = true
